{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1V5Nn6zZ-f7xHh9iDFAANN4dw2oV0BcYu","timestamp":1756927275067},{"file_id":"1UNP8sYYwxNRoU21wOPmhODCenVUugnph","timestamp":1756828626609}],"authorship_tag":"ABX9TyMMYSJE/aXxPU2DFFVgZr3M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### PART 2 Use to convert a single PDF to images, then convert and use a single image in an API call."],"metadata":{"id":"uJgBI4H4TDGH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-SGZPhHS-ntM"},"outputs":[],"source":["# @title Install Libraries\n","\n","!pip install -q openai\n","!pip install -q pdf2image\n","!apt-get install -y -q poppler-utils\n","!pip install -q Pillow\n","!pip install -q IPython"]},{"cell_type":"code","source":["# @title Import Dependencies\n","\n","from openai import OpenAI\n","import os\n","import json\n","import logging\n","from pdf2image import convert_from_path\n","from google.colab import drive\n","from openai.types.chat import ChatCompletionMessageParam\n","import base64\n","from glob import glob\n","from PIL import Image\n","from IPython.display import Image, Markdown, display"],"metadata":{"id":"Tr1TY_Tk-zGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Mount Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"bxZHCSu8-5wo","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title CD to Project Directory\n","\n","# Change the directory to where your project files are located\n","%cd /content/drive/MyDrive/Templates/ReadingPDFImages"],"metadata":{"id":"Bz2J-QtW--QA","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Configure Error Logging\n","\n","log_file = 'config_loader.log'\n","logging.basicConfig(\n","    filename=log_file,\n","    level=logging.ERROR,  # Only log errors and above (ERROR, CRITICAL)\n","    format='%(asctime)s - %(levelname)s - %(message)s'\n",")"],"metadata":{"id":"i3NTQb3zG6Xd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title FUNCTION: PDF2Images\n","\n","def PDF2Images(pdf_file: str, output_folder: str):\n","\n","  if not os.path.exists(output_folder):\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","  # convert PDF to images\n","  images = convert_from_path(pdf_file)\n","\n","  image_paths = []\n","\n","  # Save images and paths\n","  for i, image in enumerate(images):\n","    image_path = os.path.join(output_folder, f\"page{i+1}.jpg\")\n","    image.save(image_path, \"JPEG\")\n","    image_paths.append(image_path)\n","\n","  return image_paths"],"metadata":{"id":"GvWS9kg48vlH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Define Paths & call PDF2Images function\n","\n","pdf_file =  \"/content/drive/MyDrive/Templates/ReadingPDFImages/pdf_file/things-mother-used-to-make.pdf\"\n","output_folder = \"/content/drive/MyDrive/Templates/ReadingPDFImages/images/\"\n","\n","PDF2Images(pdf_file, output_folder)"],"metadata":{"id":"t8EHzmO2FDXO","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","## **END OF CREATING IMAGES FROM PDF**\n","---"],"metadata":{"id":"BJtaIOooJ3GK"}},{"cell_type":"markdown","source":["---\n","### **BEGIN API CALL ON IMAGE DATA**\n","---"],"metadata":{"id":"iIn0sEZGOq7T"}},{"cell_type":"code","source":["# @title Load API Key\n","\n","file_name = '/content/drive/MyDrive/config.json'\n","\n","try:\n","  if not os.path.exists(file_name):\n","    raise FileNotFoundError(f\"Config file not found at: {file_name}\")\n","\n","  with open(file_name, 'r') as file:\n","    try:\n","      config = json.load(file)\n","    except json.JSONDecodeError as e:\n","      raise ValueError(f\"Error decoding JSON: {e}\")\n","\n","  api_key = config.get(\"API_KEY\")\n","  base_url = config.get(\"OPENAI_API_BASE\")\n","\n","  if not api_key:\n","    raise KeyError(\"Missing 'API_KEY' in config.jason\")\n","  if not base_url:\n","    raise KeyError(\"Missing 'OPENAI_API_BASE' in config.jason\")\n","\n","  # Sets Environment Variables\n","  os.environ['OPENAI_API_KEY'] = config.get(\"API_KEY\")\n","  os.environ[\"OPENAI_BASE_URL\"] = config.get(\"OPENAI_API_BASE\")\n","\n","  print(\"Environment variables set successfully.\")\n","\n","except Exception as e:\n","  # Log the error to the log file\n","  logging.error(e)\n","  print(f\"An error ocurred.  Check {log_file} for details.\")"],"metadata":{"id":"-JWojgf5Da1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Connect to OPENAI API\n","\n","try:\n","    # Get the API key from environment variables\n","    api_key = os.environ.get(\"OPENAI_API_KEY\")\n","    if not api_key:\n","        raise ValueError(\"The OPENAI_API_KEY environment variable is not set.\")\n","\n","    # Initialize the OpenAI client\n","    client = OpenAI(api_key=api_key)\n","\n","    # Specify the model you want to use\n","    model = \"gpt-5\"\n","\n","    print(\"OpenAI client initialized successfully.\")\n","\n","except Exception as e:\n","    # Handle any errors during initialization\n","    logging.error(e)\n","    print(f\"An error occurred.  Check {log_file} for details.\")"],"metadata":{"id":"vkIQDujZF0fS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Read and encode one image\n","\n","image_path = \"images/page23.jpg\"\n","\n","with open(image_path, \"rb\") as image_file:\n","  image_data = base64.b64encode(image_file.read()).decode('utf-8')"],"metadata":{"id":"EQVvZy3Bdf_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title SYSTEM PROMPT\n","\n","system_prompt  = \"\"\"\n","\n","You are an OCR/transcription engine.\n","Please analyze the content of this image, extract the recipe type, recipe name, ingredients (one per line), and instructions per the sample below.  Do not normalize or correct text beyond obvious OCR typos.\n","Never infer or guess. The recipe type can be repeated for each recipe of that type. If no ingredients are listed disregad that section and print No ingredients, then move on to the instructions.\n","\n","The output should be formated as the sample below:\n","\n","Recipe Type: BREADS\n","\\n\n","\\n\n","Recipe Name: Bannocks\n","\\n\n","\\n\n","Ingredients:\n","\\n\n","\\n\n","1 Cupful of Thick Sour Milk\\n\n","1/2 Cupful of Sugar\\n\n","1 Egg\\n\n","2 Cupfuls of Four\\n\n","1/2 Cupful of Indian Meal\\n\n","1 Teaspoonful of Soda\\\n","A pinch of Salt\\n\n","\\n\n","Instructions:\n","\\n\n","\\n\n","Make the mixture stiff enough to drop from a spoon.  Drop mixture, size of a walnut, into boiling\n","fat.  Serve warm, with maple syrup.\n","\\n\n","\\n\n","<hr />\n","\\n\n","\\n\n","\n","\"\"\""],"metadata":{"id":"cYDmqFnrKcGi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title FUNCTON: get_gpt_response\n","\n","def get_gpt_response():\n","  gpt_response = response.choices[0].message.content\n","  return display(Markdown(gpt_response))"],"metadata":{"id":"FXsrJHG_M-Mj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Create LLM Response\n","\n","response = client.chat.completions.create(\n","    model = model,\n","    messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": [\n","            \"Extract the text from this image.\",\n","            {\"type\": \"image_url\",\n","             \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\",\n","                           \"detail\": \"low\"}}\n","        ]}\n","    ],\n","    response_format={\"type\": \"text\"}\n",")"],"metadata":{"id":"ji7SShWkNb9C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title CALL FUNCTION: get_gpt_response to Display the response\n","\n","get_gpt_response()"],"metadata":{"id":"4xm5XHMbRmi9"},"execution_count":null,"outputs":[]}]}