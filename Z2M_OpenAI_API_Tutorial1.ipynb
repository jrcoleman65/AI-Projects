{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1yLwewEwbrooFnGUPCvXwxdiiKhlD8WlM","timestamp":1755891547315},{"file_id":"1dZqvCIEPohvGAzcUPb7XCEUfEbBS5bvq","timestamp":1755879723268}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### ⚡  **USING OPENAI API TEMPLATE** ⚡\n","\n","---"],"metadata":{"id":"5QIPQX8gm4g8"}},{"cell_type":"code","source":["# @title Install Libaries\n","\n","!pip install openai\n","!pip install IPython"],"metadata":{"id":"lBNaK344l7wc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756317801966,"user_tz":360,"elapsed":25991,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}},"outputId":"e9a78866-77b7-4642-b3e5-7732b2e4715a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.12/dist-packages (7.34.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from IPython) (75.2.0)\n","Collecting jedi>=0.16 (from IPython)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from IPython) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from IPython) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from IPython) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from IPython) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from IPython) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from IPython) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from IPython) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from IPython) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->IPython) (0.8.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jedi\n","Successfully installed jedi-0.19.2\n"]}]},{"cell_type":"code","source":["# @title Imports\n","\n","from openai import OpenAI\n","import json, os\n","from IPython.display import Markdown, display\n","from openai.types.chat import ChatCompletionMessageParam"],"metadata":{"id":"DIAVJMW9nsED","executionInfo":{"status":"ok","timestamp":1756317810681,"user_tz":360,"elapsed":2837,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# @title Supress Warnings (OPTIONAL)\n","\n","#import warnings\n","#warnings.filterwarnings('ignore')"],"metadata":{"id":"hqQf2ra7o_US","executionInfo":{"status":"ok","timestamp":1756317817358,"user_tz":360,"elapsed":8,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# @title Mount Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"oQKDNVmCnztD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756317836794,"user_tz":360,"elapsed":16868,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}},"outputId":"cae4c6ed-b4fa-4f6f-8163-4532ca92a84a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["# @title CD to Project Directory\n","\n","# Change the directory to where your project files are located\n","%cd \"/content/drive/MyDrive/RAGTraining/RagTrainingZM/tutorial_1/\""],"metadata":{"id":"ZD1TK6GzrESJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756317847937,"user_tz":360,"elapsed":942,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}},"outputId":"734208e7-54ad-4e31-f07d-88366d9e671e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/RAGTraining/RagTrainingZM/tutorial_1\n"]}]},{"cell_type":"code","source":["# @title Load API Key\n","\n","file_name = \"/content/drive/MyDrive/RAGTraining/RagTrainingZM/tutorial_1/config.json\"\n","\n","with open(file_name, 'r') as file:\n","  config = json.load(file)\n","  os.environ['OPENAI_API_KEY'] = config.get(\"API_KEY\")\n","  os.environ[\"OPENAI_BASE_URL\"] = config.get(\"OPENAI_API_BASE\")"],"metadata":{"id":"IjRBH21noEly","executionInfo":{"status":"ok","timestamp":1756317851098,"user_tz":360,"elapsed":797,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# @title Create System Prompt\n","\n","system_prompt = \"\"\"\n","\n","\"You are a famous recording studio executive.  Create a 4 verse song in the style of Garth Brooks\"\n","\n","\"\"\""],"metadata":{"id":"TijuWy-8p_7I","executionInfo":{"status":"ok","timestamp":1756317854129,"user_tz":360,"elapsed":3,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# @title Create User Prompt\n","\n","user_prompt = \"\"\"\n","\n","\"write a song about milk on the moon\"\n","\n","\"\"\""],"metadata":{"id":"aoOw0JPGqdux","executionInfo":{"status":"ok","timestamp":1756317877747,"user_tz":360,"elapsed":40,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# @title Create LLM Function\n","\n","# LLM Model you want to use\n","model_name = \"gpt-4o-mini\"\n","\n","# temp - between 0-2, Higher more random, lower more focused.  Use temp or top_p but not both\n","temperature = 0.5\n","\n","# Presence_penalty between -2.0 and 2.0. Increases the model's likelihood to talk about new topics\n","presence_penalty = 0\n","\n","# frequency_penalty - between -2.0 and 2.0.  Positive values penalize new tokens based on exiting frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n","frequency_penalty = 0\n","\n","# max tokens\n","max_tokens = 2048\n","\n","# response format\n","response_format = {\"type\": \"text\"}\n","\n","def llm(system_prompt,\n","        user_prompt,\n","        model_name=model_name,\n","        temperature=temperature,\n","        presence_penalty = presence_penalty,\n","        frequency_penalty = frequency_penalty,\n","        max_tokens = max_tokens,\n","        response_format =  response_format\n","        ):\n","\n","    try:\n","\n","        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n","\n","        prompt: list[ChatCompletionMessageParam] = [\n","            {'role': 'system', 'content': system_prompt},\n","            {'role': 'user', 'content': user_prompt}\n","        ]\n","\n","        # if you use any other parameters outside their defaults, you need to include them here\n","        response = client.chat.completions.create(\n","            model=model_name,\n","            messages=prompt,\n","            temperature=temperature\n","        )\n","\n","        return response.choices[0].message.content\n","\n","    except Exception as e:\n","        error_message = f\"Sorry, I encountered the following error: {e}\"\n","        print(error_message)\n","        return error_message"],"metadata":{"id":"QXI_3Lz-oWyS","executionInfo":{"status":"ok","timestamp":1756317880079,"user_tz":360,"elapsed":7,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# @title Calling the LLM Function - Assigning Value to Response Variable\n","\n","response = llm(system_prompt, user_prompt)"],"metadata":{"id":"_K4yg67wojia","executionInfo":{"status":"ok","timestamp":1756317894954,"user_tz":360,"elapsed":12375,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# @title Displaying the Response\n","\n","from IPython.display import display, Markdown\n","display(Markdown(response))"],"metadata":{"id":"sgizLJH6ppjh","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1756317904010,"user_tz":360,"elapsed":15,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}},"outputId":"c787946d-ac0e-4226-e75b-17a54586d298"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Title: Milk on the Moon**\n\n**Verse 1:**  \nOut where the stars shine bright and clear,  \nThere's a place where dreams take flight, my dear,  \nWith a silver glow and a cosmic tune,  \nI found a little farm on the milk-white moon.  \nThe cows are dancing in the lunar light,  \nMooing softly 'neath the starry night,  \nThey’re grazing on stardust, oh what a sight,  \nPouring out dreams in the still of the night.\n\n**Chorus:**  \nMilk on the moon, oh what a surprise,  \nCreamy and dreamy under cosmic skies,  \nWith every sip, you can taste the stars,  \nA little piece of heaven, no matter where you are.  \nSo raise your glass to the galaxy's boon,  \nLet’s toast to the magic of milk on the moon.\n\n**Verse 2:**  \nThe astronauts come, with their helmets on tight,  \nSearching for treasures in the pale moonlight,  \nBut what they find is a milky stream,  \nFlowing with wonders, like a sweet, wild dream.  \nThey gather ‘round and laugh with delight,  \nSipping that nectar, everything feels right,  \nIn zero gravity, they lift up their cheers,  \nToasting to memories that’ll last through the years.\n\n**Chorus:**  \nMilk on the moon, oh what a surprise,  \nCreamy and dreamy under cosmic skies,  \nWith every sip, you can taste the stars,  \nA little piece of heaven, no matter where you are.  \nSo raise your glass to the galaxy's boon,  \nLet’s toast to the magic of milk on the moon.\n\n**Verse 3:**  \nNow back on Earth, when the night turns to dawn,  \nI’ll dream of that place where the milky cows yawn,  \nWith a heart full of wonder, I’ll always believe,  \nThat magic can happen if you just dare to dream.  \nSo I’ll keep my eyes on the skies up above,  \nFor the moon holds a secret, a story of love,  \nAnd when I close my eyes, I can still see the light,  \nOf milk on the moon, shining ever so bright.\n\n**Chorus:**  \nMilk on the moon, oh what a surprise,  \nCreamy and dreamy under cosmic skies,  \nWith every sip, you can taste the stars,  \nA little piece of heaven, no matter where you are.  \nSo raise your glass to the galaxy's boon,  \nLet’s toast to the magic of milk on the moon.\n\n**Outro:**  \nSo if you ever find yourself feeling blue,  \nJust look to the heavens, let your heart renew,  \nFor there’s milk on the moon, waiting just for you,  \nA taste of the cosmos, a love that rings true."},"metadata":{}}]},{"cell_type":"markdown","source":["---\n","### **IMAGES SECTION**\n","---\n","\n","\n","\n","\n","\n"],"metadata":{"id":"JlDClQMoeCLT"}},{"cell_type":"code","source":["# @title URL of an image we will use later\n","url = \"https://upload.wikimedia.org/wikipedia/commons/7/71/Cow_and_calf_elk_%287437504452%29.jpg\""],"metadata":{"id":"6SitzaqWWesJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Create Image System Prompt\n","\n","image_system_prompt = \"\"\"\n","\n","\"\"\""],"metadata":{"id":"hug5nMC6fV9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Create Image User Prompt\n","\n","image_user_prompt = \"\"\"\n","\n","user_content = [\n","    {\"type\": \"text\",\n","     \"text\": \"Describe the image\"},\n","    {\"type\": \"image_url\",\n","     \"image_url\": {\n","         \"url\": url,\n","         \"detail\":\"high\"\n","     }}\n","]\n","\n","\"\"\""],"metadata":{"id":"sZ2kfouYfXmK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Create IMAGES LLM Function\n","\n","# LLM Model you want to use\n","model_name = \"gpt-4o-mini\"\n","\n","# temp - between 0-2, Higher more random, lower more focused.  Use temp or top_p but not both\n","temperature = 0.5\n","\n","# Presence_penalty between -2.0 and 2.0. Increases the model's likelihood to talk about new topics\n","presence_penalty = 0\n","\n","# frequency_penalty - between -2.0 and 2.0.  Positive values penalize new tokens based on exiting frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n","frequency_penalty = 0\n","\n","# max tokens\n","max_tokens = 2048\n","\n","# response format\n","response_format = {\"type\": \"text\"}\n","\n","def image_llm(system_prompt,\n","        user_prompt,\n","        model_name=model_name,\n","        temperature=temperature,\n","        presence_penalty = presence_penalty,\n","        frequency_penalty = frequency_penalty,\n","        max_tokens = max_tokens,\n","        response_format =  response_format\n","        ):\n","\n","    try:\n","\n","        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n","\n","        prompt: list[ChatCompletionMessageParam] = [\n","            {'role': 'system', 'content': image_system_prompt},\n","            {'role': 'user', 'content': image_user_prompt}\n","        ]\n","\n","        # if you use any other parameters outside their defaults, you need to include them here\n","        response = client.chat.completions.create(\n","            model=model_name,\n","            messages = [\n","                {\"role\": \"user\", \"content\": user_content}\n","            ],\n","            temperature=temperature\n","        )\n","\n","        return response.choices[0].message.content\n","\n","    except Exception as e:\n","        error_message = f\"Sorry, I encountered the following error: {e}\"\n","        print(error_message)\n","        return error_message"],"metadata":{"id":"ChLaGA6_d9mM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Using chat.completions\n","\n","response = image_llm(image_system_prompt, image_user_prompt)"],"metadata":{"id":"mp8k5pGIbvTN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Displaying the Response\n","\n","from IPython.display import display, Markdown\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"W8OtjugtfHIL","executionInfo":{"status":"ok","timestamp":1755916038905,"user_tz":360,"elapsed":11,"user":{"displayName":"John Coleman","userId":"08155288022400272840"}},"outputId":"6929f6e6-35ce-4c02-944f-511c6867840a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The image depicts a mother elk and her calf in a natural setting. The calf, which appears to be quite young and still wet, is nursing from the mother. The mother elk is standing, gently leaning down towards the calf. The background consists of green grass and some vegetation, with a stone wall partially visible. The scene conveys a sense of tenderness and nurturing between the two animals."},"metadata":{}}]}]}